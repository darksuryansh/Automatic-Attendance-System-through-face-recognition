{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n"
     ]
    }
   ],
   "source": [
    "from deepface import DeepFace\n",
    "import cv2\n",
    "\n",
    "def grab_facial_areas(img, detector_backend=\"opencv\", threshold=130, anti_spoofing=True, spoof_threshold=0.8):\n",
    "    try:\n",
    "        face_objs = DeepFace.extract_faces(\n",
    "            img_path=img,\n",
    "            detector_backend=detector_backend,\n",
    "            anti_spoofing=anti_spoofing\n",
    "        )\n",
    "        faces = []\n",
    "        for face_obj in face_objs:\n",
    "            if face_obj[\"facial_area\"][\"w\"] > threshold:\n",
    "                is_real = face_obj[\"is_real\"] and (face_obj[\"antispoof_score\"] >= spoof_threshold)\n",
    "                faces.append((\n",
    "                    face_obj[\"facial_area\"][\"x\"],\n",
    "                    face_obj[\"facial_area\"][\"y\"],\n",
    "                    face_obj[\"facial_area\"][\"w\"],\n",
    "                    face_obj[\"facial_area\"][\"h\"],\n",
    "                    is_real,\n",
    "                    face_obj[\"antispoof_score\"]\n",
    "                ))\n",
    "        return faces\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return []\n",
    "\n",
    "def main():\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    while True:\n",
    "        _, img = cap.read()\n",
    "        faces = grab_facial_areas(img, anti_spoofing=True, spoof_threshold=0.8)  # Adjust threshold here (0.8 = 80%)\n",
    "        if faces:\n",
    "            for x, y, w, h, is_real, score in faces:\n",
    "                color = (0, 255, 0) if is_real else (0, 0, 255)\n",
    "                label = \"Real\" if is_real else \"Spoof\"\n",
    "                cv2.rectangle(img, (x, y), (x + w, y + h), color, 2)\n",
    "                cv2.putText(img, f\"{label} - {score:.2f}\", (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)\n",
    "        cv2.imshow(\"Anti-Spoofing Demo\", img)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 574 encodings for 6 people\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pickle\n",
    "import numpy as np\n",
    "from deepface import DeepFace\n",
    "from face_recognition import face_encodings, face_distance\n",
    "\n",
    "# Configuration\n",
    "ENCODINGS_FILE = 'data/encodings.pkl'\n",
    "SPOOF_THRESHOLD = 0.7  # Minimum score to consider face real\n",
    "RECOGNITION_THRESHOLD = 0.5  # Face recognition tolerance (lower is stricter)\n",
    "DETECTOR_BACKEND = \"opencv\"  # or \"retinaface\", \"mtcnn\", etc.\n",
    "\n",
    "def load_encodings():\n",
    "    \"\"\"Load facial encodings from PKL file\"\"\"\n",
    "    try:\n",
    "        with open(ENCODINGS_FILE, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "        print(f\"Loaded {len(data['encodings'])} encodings for {len(set(data['names']))} people\")\n",
    "        return data['encodings'], data['names']\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading encodings: {e}\")\n",
    "        return [], []\n",
    "\n",
    "def extract_face_encodings(face_img):\n",
    "    \"\"\"Extract 128D face encodings\"\"\"\n",
    "    rgb_face = cv2.cvtColor(face_img, cv2.COLOR_BGR2RGB)\n",
    "    encodings = face_encodings(rgb_face)\n",
    "    return encodings[0] if encodings else None\n",
    "\n",
    "def recognize_face(face_encoding, known_encodings, known_names):\n",
    "    \"\"\"Compare face with known encodings\"\"\"\n",
    "    distances = face_distance(known_encodings, face_encoding)\n",
    "    best_match_idx = np.argmin(distances)\n",
    "    min_distance = distances[best_match_idx]\n",
    "    \n",
    "    if min_distance <= RECOGNITION_THRESHOLD:\n",
    "        return known_names[best_match_idx], 1 - min_distance\n",
    "    return None, None\n",
    "\n",
    "def main():\n",
    "    # Load known faces\n",
    "    known_encodings, known_names = load_encodings()\n",
    "    if not known_encodings:\n",
    "        print(\"No encodings found! Please create encodings first.\")\n",
    "        return\n",
    "\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open video capture\")\n",
    "        return\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Error: Couldn't read frame\")\n",
    "            break\n",
    "\n",
    "        # Detect faces with anti-spoofing\n",
    "        try:\n",
    "            face_objs = DeepFace.extract_faces(\n",
    "                img_path=frame,\n",
    "                detector_backend=DETECTOR_BACKEND,\n",
    "                anti_spoofing=True,\n",
    "                enforce_detection=False\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"Face detection error: {e}\")\n",
    "            continue\n",
    "\n",
    "        for face_obj in face_objs:\n",
    "            x, y, w, h = face_obj[\"facial_area\"][\"x\"], face_obj[\"facial_area\"][\"y\"], \\\n",
    "                         face_obj[\"facial_area\"][\"w\"], face_obj[\"facial_area\"][\"h\"]\n",
    "            \n",
    "            # Check if face is real\n",
    "            is_real = face_obj[\"is_real\"] and (face_obj[\"antispoof_score\"] >= SPOOF_THRESHOLD)\n",
    "            \n",
    "            if is_real:\n",
    "                # Extract face ROI and get encoding\n",
    "                face_roi = frame[y:y+h, x:x+w]\n",
    "                face_encoding = extract_face_encodings(face_roi)\n",
    "                \n",
    "                if face_encoding is not None:\n",
    "                    # Recognize face\n",
    "                    name, confidence = recognize_face(face_encoding, known_encodings, known_names)\n",
    "                    label = f\"{name} ({confidence:.2f})\" if name else \"Unknown\"\n",
    "                    color = (0, 255, 0)  # Green for recognized\n",
    "                else:\n",
    "                    label = \"No encoding\"\n",
    "                    color = (0, 255, 255)  # Yellow for detection issues\n",
    "            else:\n",
    "                label = f\"Spoof ({face_obj['antispoof_score']:.2f})\"\n",
    "                color = (0, 0, 255)  # Red for spoofed\n",
    "\n",
    "            # Draw bounding box and label\n",
    "            cv2.rectangle(frame, (x, y), (x+w, y+h), color, 2)\n",
    "            cv2.putText(frame, label, (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)\n",
    "\n",
    "        cv2.imshow(\"Secure Face Recognition\", frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(795, 85, 307, 307, True, 0.9433561861515045), (0, 216, 356, 356, True, 0.8553857207298279)]\n",
      "[(777, 122, 335, 335, True, 0.6304318904876709), (158, 373, 391, 346, False, 0.5825231969356537)]\n",
      "[(779, 102, 305, 305, True, 0.527402475476265), (168, 372, 382, 347, True, 0.624309629201889)]\n",
      "[(798, 94, 290, 290, True, 0.7153775840997696)]\n",
      "[(782, 97, 303, 303, True, 0.6742955148220062), (156, 377, 380, 342, True, 0.8004303574562073)]\n",
      "[(133, 334, 392, 385, False, 0.5912452191114426), (793, 104, 333, 333, True, 0.7020304799079895)]\n",
      "[(777, 107, 317, 317, False, 0.51532331854105), (0, 213, 322, 322, True, 0.9603157937526703)]\n",
      "[(786, 102, 306, 306, True, 0.6160606741905212)]\n",
      "[(788, 94, 307, 307, True, 0.6917622834444046)]\n",
      "[(781, 93, 309, 309, True, 0.8405901491641998)]\n",
      "[(780, 92, 305, 305, True, 0.965551108121872)]\n",
      "[(779, 89, 312, 312, True, 0.9442227482795715)]\n",
      "[(781, 91, 308, 308, True, 0.9450961947441101)]\n",
      "[(783, 91, 304, 304, True, 0.9221530556678772), (0, 221, 335, 335, True, 0.5038981884717941)]\n",
      "[(781, 91, 311, 311, True, 0.8638195693492889), (11, 231, 331, 331, False, 0.7553673386573792)]\n",
      "[(787, 95, 305, 305, True, 0.8524842262268066), (24, 233, 330, 330, False, 0.7849165797233582)]\n",
      "[(785, 94, 306, 306, True, 0.8103097975254059), (43, 246, 318, 318, False, 0.8189013600349426)]\n",
      "[(787, 91, 311, 311, True, 0.8895184397697449), (49, 252, 330, 330, False, 0.7912830710411072)]\n",
      "[(815, 79, 274, 274, True, 0.8114270567893982)]\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from deepface import DeepFace\n",
    "import cv2\n",
    "\n",
    "def grab_facial_areas(img, detector_backend=\"opencv\", threshold=130, anti_spoofing=False):\n",
    "    try:\n",
    "        face_objs = DeepFace.extract_faces(img_path=img, detector_backend=detector_backend, expand_percentage=0, anti_spoofing=anti_spoofing)\n",
    "        faces = [\n",
    "            (\n",
    "                face_obj[\"facial_area\"][\"x\"],\n",
    "                face_obj[\"facial_area\"][\"y\"],\n",
    "                face_obj[\"facial_area\"][\"w\"],\n",
    "                face_obj[\"facial_area\"][\"h\"],\n",
    "                face_obj[\"is_real\"],\n",
    "                face_obj[\"antispoof_score\"]\n",
    "            )\n",
    "            for face_obj in face_objs\n",
    "            if face_obj[\"facial_area\"][\"w\"] > threshold\n",
    "        ]\n",
    "        return faces\n",
    "    except Exception as e:\n",
    "        print(str(e))\n",
    "        return []\n",
    "\n",
    "def main():\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    while True:\n",
    "        _, img = cap.read()\n",
    "        faces = grab_facial_areas(img, anti_spoofing=True)\n",
    "        if faces:\n",
    "            print(faces)\n",
    "            for x, y, w, h, is_real, antispoof_score in faces:\n",
    "                if is_real:\n",
    "                    color = (0, 255, 0)\n",
    "                    real = \"Real\"\n",
    "                else:\n",
    "                    color = (0, 0, 255)\n",
    "                    real = \"Spoof\"\n",
    "                cv2.rectangle(img, (x, y), (x + w, y + h), color, 2)\n",
    "                cv2.rectangle(img, (x, y+h), (x+w, y+h+30), color, cv2.FILLED)\n",
    "                cv2.putText(img, f\"{real} - {antispoof_score:.2f}%\", (x+5, y+h+20), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 0), 2)\n",
    "        cv2.imshow(\"frame\", img)\n",
    "        key = cv2.waitKey(1)\n",
    "        if key == ord(\"q\"):\n",
    "            break\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 785 encodings for 9 people\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 22] Invalid argument: 'C:\\\\pc\\\\Projects\\\\Project\\\\capturing_dataset\\\\data\\x07ttendance.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 171\u001b[0m\n\u001b[0;32m    168\u001b[0m     cv2\u001b[38;5;241m.\u001b[39mdestroyAllWindows()\n\u001b[0;32m    170\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 171\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[14], line 137\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m can_mark_attendance(name, attendance_df):\n\u001b[0;32m    136\u001b[0m     attendance_df \u001b[38;5;241m=\u001b[39m mark_attendance(name, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPresent\u001b[39m\u001b[38;5;124m\"\u001b[39m, attendance_df)\n\u001b[1;32m--> 137\u001b[0m     \u001b[43msave_attendance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattendance_df\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    138\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttendance marked for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    139\u001b[0m     recently_recognized[name] \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mnow()\n",
      "Cell \u001b[1;32mIn[14], line 38\u001b[0m, in \u001b[0;36msave_attendance\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msave_attendance\u001b[39m(df):\n\u001b[0;32m     37\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Save attendance records to CSV\"\"\"\u001b[39;00m\n\u001b[1;32m---> 38\u001b[0m     \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mATTENDANCE_FILE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\suryansh\\anaconda3\\envs\\face_recognition_env\\lib\\site-packages\\pandas\\core\\generic.py:3772\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[0;32m   3761\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_frame()\n\u001b[0;32m   3763\u001b[0m formatter \u001b[38;5;241m=\u001b[39m DataFrameFormatter(\n\u001b[0;32m   3764\u001b[0m     frame\u001b[38;5;241m=\u001b[39mdf,\n\u001b[0;32m   3765\u001b[0m     header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3769\u001b[0m     decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[0;32m   3770\u001b[0m )\n\u001b[1;32m-> 3772\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameRenderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3773\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3774\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlineterminator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3775\u001b[0m \u001b[43m    \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3776\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3777\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3778\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3779\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquoting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3780\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3781\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3782\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3783\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3784\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquotechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquotechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3785\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3786\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdoublequote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3787\u001b[0m \u001b[43m    \u001b[49m\u001b[43mescapechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mescapechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3788\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3789\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\suryansh\\anaconda3\\envs\\face_recognition_env\\lib\\site-packages\\pandas\\io\\formats\\format.py:1186\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[0;32m   1165\u001b[0m     created_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1167\u001b[0m csv_formatter \u001b[38;5;241m=\u001b[39m CSVFormatter(\n\u001b[0;32m   1168\u001b[0m     path_or_buf\u001b[38;5;241m=\u001b[39mpath_or_buf,\n\u001b[0;32m   1169\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1184\u001b[0m     formatter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt,\n\u001b[0;32m   1185\u001b[0m )\n\u001b[1;32m-> 1186\u001b[0m \u001b[43mcsv_formatter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[0;32m   1189\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[1;32mc:\\Users\\suryansh\\anaconda3\\envs\\face_recognition_env\\lib\\site-packages\\pandas\\io\\formats\\csvs.py:240\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    236\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    237\u001b[0m \u001b[38;5;124;03mCreate the writer & save.\u001b[39;00m\n\u001b[0;32m    238\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    239\u001b[0m \u001b[38;5;66;03m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[1;32m--> 240\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    241\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    242\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    243\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    244\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    245\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    246\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    247\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[0;32m    248\u001b[0m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter \u001b[38;5;241m=\u001b[39m csvlib\u001b[38;5;241m.\u001b[39mwriter(\n\u001b[0;32m    250\u001b[0m         handles\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[0;32m    251\u001b[0m         lineterminator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    256\u001b[0m         quotechar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquotechar,\n\u001b[0;32m    257\u001b[0m     )\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save()\n",
      "File \u001b[1;32mc:\\Users\\suryansh\\anaconda3\\envs\\face_recognition_env\\lib\\site-packages\\pandas\\io\\common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    854\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    855\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    856\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    857\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    858\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 859\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    860\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    862\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    863\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    864\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    865\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    866\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    867\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    868\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mOSError\u001b[0m: [Errno 22] Invalid argument: 'C:\\\\pc\\\\Projects\\\\Project\\\\capturing_dataset\\\\data\\x07ttendance.csv'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from deepface import DeepFace\n",
    "from face_recognition import face_encodings, face_distance\n",
    "import os\n",
    "\n",
    "# Configuration\n",
    "ENCODINGS_FILE = 'C:\\pc\\Projects\\Project\\capturing_dataset\\data\\encodings.pkl'\n",
    "ATTENDANCE_FILE = 'C:\\pc\\Projects\\Project\\capturing_dataset\\data\\attendance.csv'\n",
    "SPOOF_THRESHOLD = 0.7  # Minimum score to consider face real\n",
    "RECOGNITION_THRESHOLD = 0.5  # Face recognition tolerance (lower is stricter)\n",
    "DETECTOR_BACKEND = \"opencv\"  # or \"retinaface\", \"mtcnn\", etc.\n",
    "ATTENDANCE_INTERVAL = timedelta(hours=1)  # Time between allowed attendance marks\n",
    "\n",
    "def load_encodings():\n",
    "    \"\"\"Load facial encodings from PKL file\"\"\"\n",
    "    try:\n",
    "        with open(ENCODINGS_FILE, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "        print(f\"Loaded {len(data['encodings'])} encodings for {len(set(data['names']))} people\")\n",
    "        return data['encodings'], data['names']\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading encodings: {e}\")\n",
    "        return [], []\n",
    "\n",
    "def load_attendance():\n",
    "    \"\"\"Load attendance records from CSV\"\"\"\n",
    "    if os.path.exists(ATTENDANCE_FILE):\n",
    "        df = pd.read_csv(ATTENDANCE_FILE, parse_dates=['timestamp'])\n",
    "        return df\n",
    "    return pd.DataFrame(columns=['name', 'timestamp', 'status'])\n",
    "\n",
    "def save_attendance(df):\n",
    "    \"\"\"Save attendance records to CSV\"\"\"\n",
    "    df.to_csv(ATTENDANCE_FILE, index=False)\n",
    "\n",
    "def can_mark_attendance(name, attendance_df):\n",
    "    \"\"\"Check if attendance can be marked (not marked in last hour)\"\"\"\n",
    "    if name is None:\n",
    "        return False\n",
    "    \n",
    "    now = datetime.now()\n",
    "    last_attendance = attendance_df[attendance_df['name'] == name]\n",
    "    \n",
    "    if not last_attendance.empty:\n",
    "        last_time = pd.to_datetime(last_attendance['timestamp'].iloc[-1])\n",
    "        return now - last_time >= ATTENDANCE_INTERVAL\n",
    "    return True\n",
    "\n",
    "def mark_attendance(name, status, attendance_df):\n",
    "    \"\"\"Mark attendance in the dataframe\"\"\"\n",
    "    if name is None:\n",
    "        return attendance_df\n",
    "    \n",
    "    now = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    new_entry = pd.DataFrame([[name, now, status]], \n",
    "                            columns=['name', 'timestamp', 'status'])\n",
    "    return pd.concat([attendance_df, new_entry], ignore_index=True)\n",
    "\n",
    "def extract_face_encodings(face_img):\n",
    "    \"\"\"Extract 128D face encodings\"\"\"\n",
    "    rgb_face = cv2.cvtColor(face_img, cv2.COLOR_BGR2RGB)\n",
    "    encodings = face_encodings(rgb_face)\n",
    "    return encodings[0] if encodings else None\n",
    "\n",
    "def recognize_face(face_encoding, known_encodings, known_names):\n",
    "    \"\"\"Compare face with known encodings\"\"\"\n",
    "    distances = face_distance(known_encodings, face_encoding)\n",
    "    best_match_idx = np.argmin(distances)\n",
    "    min_distance = distances[best_match_idx]\n",
    "    \n",
    "    if min_distance <= RECOGNITION_THRESHOLD:\n",
    "        return known_names[best_match_idx], 1 - min_distance\n",
    "    return None, None\n",
    "\n",
    "def main():\n",
    "    # Load known faces\n",
    "    known_encodings, known_names = load_encodings()\n",
    "    if not known_encodings:\n",
    "        print(\"No encodings found! Please create encodings first.\")\n",
    "        return\n",
    "\n",
    "    # Load attendance records\n",
    "    attendance_df = load_attendance()\n",
    "    \n",
    "    cap = cv2.VideoCapture(0)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open video capture\")\n",
    "        return\n",
    "\n",
    "    # Track recently recognized faces to avoid spamming attendance\n",
    "    recently_recognized = {}\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Error: Couldn't read frame\")\n",
    "            break\n",
    "\n",
    "        # Detect faces with anti-spoofing\n",
    "        try:\n",
    "            face_objs = DeepFace.extract_faces(\n",
    "                img_path=frame,\n",
    "                detector_backend=DETECTOR_BACKEND,\n",
    "                anti_spoofing=True,\n",
    "                enforce_detection=False\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"Face detection error: {e}\")\n",
    "            continue\n",
    "\n",
    "        for face_obj in face_objs:\n",
    "            x, y, w, h = face_obj[\"facial_area\"][\"x\"], face_obj[\"facial_area\"][\"y\"], \\\n",
    "                         face_obj[\"facial_area\"][\"w\"], face_obj[\"facial_area\"][\"h\"]\n",
    "            \n",
    "            # Check if face is real\n",
    "            is_real = face_obj[\"is_real\"] and (face_obj[\"antispoof_score\"] >= SPOOF_THRESHOLD)\n",
    "            \n",
    "            if is_real:\n",
    "                # Extract face ROI and get encoding\n",
    "                face_roi = frame[y:y+h, x:x+w]\n",
    "                face_encoding = extract_face_encodings(face_roi)\n",
    "                \n",
    "                if face_encoding is not None:\n",
    "                    # Recognize face\n",
    "                    name, confidence = recognize_face(face_encoding, known_encodings, known_names)\n",
    "                    label = f\"{name} ({confidence:.2f})\" if name else \"Unknown\"\n",
    "                    color = (0, 255, 0)  # Green for recognized\n",
    "                    \n",
    "                    # Check if we should mark attendance\n",
    "                    if name and name not in recently_recognized:\n",
    "                        if can_mark_attendance(name, attendance_df):\n",
    "                            attendance_df = mark_attendance(name, \"Present\", attendance_df)\n",
    "                            save_attendance(attendance_df)\n",
    "                            print(f\"Attendance marked for {name}\")\n",
    "                            recently_recognized[name] = datetime.now()\n",
    "                else:\n",
    "                    label = \"No encoding\"\n",
    "                    color = (0, 255, 255)  # Yellow for detection issues\n",
    "            else:\n",
    "                label = f\"Spoof ({face_obj['antispoof_score']:.2f})\"\n",
    "                color = (0, 0, 255)  # Red for spoofed\n",
    "                \n",
    "                # Mark spoofing attempt in log\n",
    "                if \"spoof_attempt\" not in recently_recognized or \\\n",
    "                   (datetime.now() - recently_recognized.get(\"spoof_attempt\", datetime.min)).seconds > 60:\n",
    "                    attendance_df = mark_attendance(\"Spoof Attempt\", \"Spoofed\", attendance_df)\n",
    "                    save_attendance(attendance_df)\n",
    "                    recently_recognized[\"spoof_attempt\"] = datetime.now()\n",
    "\n",
    "            # Draw bounding box and label\n",
    "            cv2.rectangle(frame, (x, y), (x+w, y+h), color, 2)\n",
    "            cv2.putText(frame, label, (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)\n",
    "\n",
    "        # Clean up recently recognized dictionary\n",
    "        current_time = datetime.now()\n",
    "        recently_recognized = {k: v for k, v in recently_recognized.items() \n",
    "                             if current_time - v < timedelta(minutes=5)}\n",
    "\n",
    "        cv2.imshow(\"Secure Face Recognition\", frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loaded 687 encodings for 8 people\n",
      "[ERROR] Error loading data: unconverted data remains when parsing with format \"%Y-%m-%d %H:%M:%S\": \".356669\", at position 2. You might want to try:\n",
      "    - passing `format` if your strings have a consistent format;\n",
      "    - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "    - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import ttk, messagebox, filedialog\n",
    "import cv2\n",
    "from PIL import Image, ImageTk\n",
    "import threading\n",
    "import queue\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from deepface import DeepFace\n",
    "from face_recognition import face_encodings, face_distance\n",
    "import os\n",
    "import time\n",
    "\n",
    "class AttendanceSystem:\n",
    "    def __init__(self):\n",
    "        # Configuration\n",
    "        self.ENCODINGS_FILE = 'data/encodings.pkl'\n",
    "        self.ATTENDANCE_FILE = 'data/attendance.csv'\n",
    "        self.TIMETABLE_FILE = 'data/timetable.csv'\n",
    "        self.SPOOF_THRESHOLD = 0.7\n",
    "        self.RECOGNITION_THRESHOLD = 0.5\n",
    "        self.DETECTOR_BACKEND = \"opencv\"\n",
    "        self.ATTENDANCE_INTERVAL = timedelta(hours=1)\n",
    "        \n",
    "        # State variables\n",
    "        self.running = False\n",
    "        self.camera = None\n",
    "        self.known_encodings = []\n",
    "        self.known_names = []\n",
    "        self.attendance_df = pd.DataFrame()\n",
    "        self.timetable_df = pd.DataFrame()\n",
    "        self.recently_recognized = {}\n",
    "        self.current_subject = None\n",
    "        self.current_class = None\n",
    "        \n",
    "        # Initialize GUI\n",
    "        self.root = tk.Tk()\n",
    "        self.root.title(\"Smart Attendance System\")\n",
    "        self.root.geometry(\"1200x800\")\n",
    "        self.root.protocol(\"WM_DELETE_WINDOW\", self.on_close)\n",
    "        \n",
    "        # Setup styles\n",
    "        self.setup_styles()\n",
    "        \n",
    "        # Build UI\n",
    "        self.create_widgets()\n",
    "        \n",
    "        # Load data\n",
    "        self.load_data()\n",
    "        \n",
    "        # Start camera thread\n",
    "        self.start_camera()\n",
    "    \n",
    "    def setup_styles(self):\n",
    "        style = ttk.Style()\n",
    "        style.configure('TFrame', background='#f0f0f0')\n",
    "        style.configure('TLabel', background='#f0f0f0', font=('Helvetica', 10))\n",
    "        style.configure('Header.TLabel', font=('Helvetica', 12, 'bold'))\n",
    "        style.configure('TButton', font=('Helvetica', 10))\n",
    "        style.configure('Primary.TButton', foreground='white', background='#0078d7')\n",
    "        style.configure('Success.TButton', foreground='white', background='#4CAF50')\n",
    "        style.configure('Danger.TButton', foreground='white', background='#f44336')\n",
    "        style.configure('TCombobox', font=('Helvetica', 10))\n",
    "        style.configure('Treeview', font=('Helvetica', 10), rowheight=25)\n",
    "        style.configure('Treeview.Heading', font=('Helvetica', 10, 'bold'))\n",
    "    \n",
    "    def create_widgets(self):\n",
    "        # Main container\n",
    "        main_frame = ttk.Frame(self.root)\n",
    "        main_frame.pack(fill=tk.BOTH, expand=True, padx=10, pady=10)\n",
    "        \n",
    "        # Left panel - Camera and controls\n",
    "        left_panel = ttk.Frame(main_frame, width=600)\n",
    "        left_panel.pack(side=tk.LEFT, fill=tk.BOTH, expand=True)\n",
    "        \n",
    "        # Camera frame\n",
    "        camera_frame = ttk.LabelFrame(left_panel, text=\"Live Camera Feed\")\n",
    "        camera_frame.pack(fill=tk.BOTH, expand=True, padx=5, pady=5)\n",
    "        \n",
    "        self.camera_label = ttk.Label(camera_frame)\n",
    "        self.camera_label.pack(fill=tk.BOTH, expand=True)\n",
    "        \n",
    "        # Controls frame\n",
    "        controls_frame = ttk.Frame(left_panel)\n",
    "        controls_frame.pack(fill=tk.X, padx=5, pady=5)\n",
    "        \n",
    "        self.start_btn = ttk.Button(\n",
    "            controls_frame, text=\"Start\", style='Success.TButton',\n",
    "            command=self.start_recognition\n",
    "        )\n",
    "        self.start_btn.pack(side=tk.LEFT, padx=5)\n",
    "        \n",
    "        self.stop_btn = ttk.Button(\n",
    "            controls_frame, text=\"Stop\", style='Danger.TButton',\n",
    "            command=self.stop_recognition, state=tk.DISABLED\n",
    "        )\n",
    "        self.stop_btn.pack(side=tk.LEFT, padx=5)\n",
    "        \n",
    "        self.export_btn = ttk.Button(\n",
    "            controls_frame, text=\"Export Attendance\", style='Primary.TButton',\n",
    "            command=self.export_attendance\n",
    "        )\n",
    "        self.export_btn.pack(side=tk.RIGHT, padx=5)\n",
    "        \n",
    "        # Status frame\n",
    "        status_frame = ttk.LabelFrame(left_panel, text=\"System Status\")\n",
    "        status_frame.pack(fill=tk.X, padx=5, pady=5)\n",
    "        \n",
    "        self.status_label = ttk.Label(status_frame, text=\"System ready. Click Start to begin recognition.\")\n",
    "        self.status_label.pack(fill=tk.X, padx=5, pady=5)\n",
    "        \n",
    "        # Right panel - Attendance and timetable\n",
    "        right_panel = ttk.Frame(main_frame, width=400)\n",
    "        right_panel.pack(side=tk.RIGHT, fill=tk.BOTH, expand=True)\n",
    "        \n",
    "        # Timetable controls\n",
    "        timetable_control_frame = ttk.LabelFrame(right_panel, text=\"Timetable Configuration\")\n",
    "        timetable_control_frame.pack(fill=tk.X, padx=5, pady=5)\n",
    "        \n",
    "        ttk.Label(timetable_control_frame, text=\"Current Class:\").grid(row=0, column=0, sticky=tk.W, padx=5, pady=2)\n",
    "        self.class_combo = ttk.Combobox(timetable_control_frame, state=\"readonly\")\n",
    "        self.class_combo.grid(row=0, column=1, sticky=tk.EW, padx=5, pady=2)\n",
    "        self.class_combo.bind(\"<<ComboboxSelected>>\", self.update_subject_options)\n",
    "        \n",
    "        ttk.Label(timetable_control_frame, text=\"Current Subject:\").grid(row=1, column=0, sticky=tk.W, padx=5, pady=2)\n",
    "        self.subject_combo = ttk.Combobox(timetable_control_frame, state=\"readonly\")\n",
    "        self.subject_combo.grid(row=1, column=1, sticky=tk.EW, padx=5, pady=2)\n",
    "        self.subject_combo.bind(\"<<ComboboxSelected>>\", self.update_current_session)\n",
    "        \n",
    "        # Attendance summary\n",
    "        summary_frame = ttk.LabelFrame(right_panel, text=\"Today's Attendance Summary\")\n",
    "        summary_frame.pack(fill=tk.X, padx=5, pady=5)\n",
    "        \n",
    "        self.summary_label = ttk.Label(summary_frame, text=\"No attendance recorded today\")\n",
    "        self.summary_label.pack(fill=tk.X, padx=5, pady=5)\n",
    "        \n",
    "        # Attendance details\n",
    "        details_frame = ttk.LabelFrame(right_panel, text=\"Attendance Details\")\n",
    "        details_frame.pack(fill=tk.BOTH, expand=True, padx=5, pady=5)\n",
    "        \n",
    "        # Treeview for attendance records\n",
    "        self.tree = ttk.Treeview(details_frame, columns=('name', 'timestamp', 'status', 'subject'), show='headings')\n",
    "        self.tree.heading('name', text='Name')\n",
    "        self.tree.heading('timestamp', text='Time')\n",
    "        self.tree.heading('status', text='Status')\n",
    "        self.tree.heading('subject', text='Subject')\n",
    "        self.tree.column('name', width=120)\n",
    "        self.tree.column('timestamp', width=120)\n",
    "        self.tree.column('status', width=80)\n",
    "        self.tree.column('subject', width=100)\n",
    "        \n",
    "        scrollbar = ttk.Scrollbar(details_frame, orient=tk.VERTICAL, command=self.tree.yview)\n",
    "        self.tree.configure(yscroll=scrollbar.set)\n",
    "        scrollbar.pack(side=tk.RIGHT, fill=tk.Y)\n",
    "        self.tree.pack(fill=tk.BOTH, expand=True)\n",
    "        \n",
    "        # Configure grid weights\n",
    "        timetable_control_frame.columnconfigure(1, weight=1)\n",
    "    \n",
    "    def load_data(self):\n",
    "        \"\"\"Load all required data files\"\"\"\n",
    "        try:\n",
    "            # Load face encodings\n",
    "            if os.path.exists(self.ENCODINGS_FILE):\n",
    "                with open(self.ENCODINGS_FILE, 'rb') as f:\n",
    "                    data = pickle.load(f)\n",
    "                self.known_encodings = data['encodings']\n",
    "                self.known_names = data['names']\n",
    "                self.update_status(f\"Loaded {len(self.known_encodings)} encodings for {len(set(self.known_names))} people\")\n",
    "            else:\n",
    "                self.update_status(\"Warning: No face encodings found!\", \"warning\")\n",
    "            \n",
    "            # Load attendance records\n",
    "            if os.path.exists(self.ATTENDANCE_FILE):\n",
    "                self.attendance_df = pd.read_csv(self.ATTENDANCE_FILE, parse_dates=['timestamp'])\n",
    "                self.update_attendance_display()\n",
    "            else:\n",
    "                self.attendance_df = pd.DataFrame(columns=['name', 'timestamp', 'status', 'subject'])\n",
    "            \n",
    "            # Load timetable\n",
    "            if os.path.exists(self.TIMETABLE_FILE):\n",
    "                self.timetable_df = pd.read_csv(self.TIMETABLE_FILE)\n",
    "                self.update_timetable_display()\n",
    "            else:\n",
    "                self.timetable_df = pd.DataFrame(columns=['class', 'subject', 'day', 'time'])\n",
    "                self.update_status(\"Warning: No timetable found!\", \"warning\")\n",
    "        except Exception as e:\n",
    "            self.update_status(f\"Error loading data: {str(e)}\", \"error\")\n",
    "    \n",
    "    def update_timetable_display(self):\n",
    "        \"\"\"Update the timetable dropdowns\"\"\"\n",
    "        if not self.timetable_df.empty:\n",
    "            classes = sorted(self.timetable_df['class'].unique())\n",
    "            self.class_combo['values'] = classes\n",
    "            if classes:\n",
    "                self.class_combo.current(0)\n",
    "                self.update_subject_options()\n",
    "    \n",
    "    def update_subject_options(self, event=None):\n",
    "        \"\"\"Update subject dropdown based on selected class\"\"\"\n",
    "        selected_class = self.class_combo.get()\n",
    "        if selected_class and not self.timetable_df.empty:\n",
    "            subjects = self.timetable_df[self.timetable_df['class'] == selected_class]['subject'].unique()\n",
    "            self.subject_combo['values'] = subjects\n",
    "            if subjects:\n",
    "                self.subject_combo.current(0)\n",
    "                self.update_current_session()\n",
    "    \n",
    "    def update_current_session(self, event=None):\n",
    "        \"\"\"Update current class and subject\"\"\"\n",
    "        self.current_class = self.class_combo.get()\n",
    "        self.current_subject = self.subject_combo.get()\n",
    "        self.update_status(f\"Current session: {self.current_class} - {self.current_subject}\")\n",
    "    \n",
    "    def start_camera(self):\n",
    "        \"\"\"Initialize camera in a separate thread\"\"\"\n",
    "        self.camera = cv2.VideoCapture(0)\n",
    "        if not self.camera.isOpened():\n",
    "            self.update_status(\"Error: Could not open video capture\", \"error\")\n",
    "            return\n",
    "        \n",
    "        self.camera_thread = threading.Thread(target=self._camera_loop, daemon=True)\n",
    "        self.camera_thread.start()\n",
    "    \n",
    "    def _camera_loop(self):\n",
    "        \"\"\"Thread for continuously capturing camera frames\"\"\"\n",
    "        while self.running or not hasattr(self, 'camera_queue'):\n",
    "            ret, frame = self.camera.read()\n",
    "            if ret:\n",
    "                if not hasattr(self, 'camera_queue'):\n",
    "                    self.camera_queue = queue.Queue(maxsize=1)\n",
    "                \n",
    "                try:\n",
    "                    # Convert to RGB and resize for display\n",
    "                    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                    frame_resized = cv2.resize(frame_rgb, (640, 480))\n",
    "                    \n",
    "                    # Put frame in queue (discard old frame if queue is full)\n",
    "                    if self.camera_queue.full():\n",
    "                        self.camera_queue.get_nowait()\n",
    "                    self.camera_queue.put(frame_resized)\n",
    "                except queue.Full:\n",
    "                    pass\n",
    "            time.sleep(0.03)  # ~30 FPS\n",
    "    \n",
    "    def update_camera_display(self):\n",
    "        \"\"\"Update the camera display in the GUI\"\"\"\n",
    "        if hasattr(self, 'camera_queue') and not self.camera_queue.empty():\n",
    "            frame = self.camera_queue.get()\n",
    "            \n",
    "            # Convert to PhotoImage\n",
    "            img = Image.fromarray(frame)\n",
    "            imgtk = ImageTk.PhotoImage(image=img)\n",
    "            \n",
    "            # Update label\n",
    "            self.camera_label.imgtk = imgtk\n",
    "            self.camera_label.configure(image=imgtk)\n",
    "        \n",
    "        # Schedule next update\n",
    "        if self.running:\n",
    "            self.root.after(30, self.update_camera_display)\n",
    "    \n",
    "    def start_recognition(self):\n",
    "        \"\"\"Start face recognition process\"\"\"\n",
    "        if not self.known_encodings:\n",
    "            messagebox.showerror(\"Error\", \"No face encodings loaded!\")\n",
    "            return\n",
    "        \n",
    "        if not self.current_subject or not self.current_class:\n",
    "            messagebox.showwarning(\"Warning\", \"Please select class and subject first!\")\n",
    "            return\n",
    "        \n",
    "        self.running = True\n",
    "        self.start_btn.config(state=tk.DISABLED)\n",
    "        self.stop_btn.config(state=tk.NORMAL)\n",
    "        \n",
    "        # Start processing thread\n",
    "        self.processing_thread = threading.Thread(target=self._processing_loop, daemon=True)\n",
    "        self.processing_thread.start()\n",
    "        \n",
    "        # Start camera display updates\n",
    "        self.update_camera_display()\n",
    "        self.update_status(\"Face recognition started\")\n",
    "    \n",
    "    def stop_recognition(self):\n",
    "        \"\"\"Stop face recognition process\"\"\"\n",
    "        self.running = False\n",
    "        self.start_btn.config(state=tk.NORMAL)\n",
    "        self.stop_btn.config(state=tk.DISABLED)\n",
    "        self.update_status(\"Face recognition stopped\")\n",
    "    \n",
    "    def _processing_loop(self):\n",
    "        \"\"\"Thread for face recognition processing\"\"\"\n",
    "        while self.running:\n",
    "            if hasattr(self, 'camera_queue') and not self.camera_queue.empty():\n",
    "                frame = self.camera_queue.get()\n",
    "                \n",
    "                # Convert back to BGR for processing\n",
    "                frame_bgr = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "                \n",
    "                try:\n",
    "                    # Detect faces with anti-spoofing\n",
    "                    face_objs = DeepFace.extract_faces(\n",
    "                        img_path=frame_bgr,\n",
    "                        detector_backend=self.DETECTOR_BACKEND,\n",
    "                        anti_spoofing=True,\n",
    "                        enforce_detection=False\n",
    "                    )\n",
    "                    \n",
    "                    for face_obj in face_objs:\n",
    "                        x, y, w, h = face_obj[\"facial_area\"][\"x\"], face_obj[\"facial_area\"][\"y\"], \\\n",
    "                                     face_obj[\"facial_area\"][\"w\"], face_obj[\"facial_area\"][\"h\"]\n",
    "                        \n",
    "                        # Check if face is real\n",
    "                        is_real = face_obj[\"is_real\"] and (face_obj[\"antispoof_score\"] >= self.SPOOF_THRESHOLD)\n",
    "                        \n",
    "                        if is_real:\n",
    "                            # Extract face ROI and get encoding\n",
    "                            face_roi = frame_bgr[y:y+h, x:x+w]\n",
    "                            face_encoding = self.extract_face_encodings(face_roi)\n",
    "                            \n",
    "                            if face_encoding is not None:\n",
    "                                # Recognize face\n",
    "                                name, confidence = self.recognize_face(face_encoding)\n",
    "                                label = f\"{name} ({confidence:.2f})\" if name else \"Unknown\"\n",
    "                                color = (0, 255, 0)  # Green for recognized\n",
    "                                \n",
    "                                # Check if we should mark attendance\n",
    "                                if name and name not in self.recently_recognized:\n",
    "                                    if self.can_mark_attendance(name):\n",
    "                                        self.mark_attendance(name, \"Present\")\n",
    "                                        self.recently_recognized[name] = datetime.now()\n",
    "                                        self.root.after(0, self.update_attendance_display)\n",
    "                        else:\n",
    "                            label = f\"Spoof ({face_obj['antispoof_score']:.2f})\"\n",
    "                            color = (0, 0, 255)  # Red for spoofed\n",
    "                            \n",
    "                            # Mark spoofing attempt in log\n",
    "                            if \"spoof_attempt\" not in self.recently_recognized or \\\n",
    "                               (datetime.now() - self.recently_recognized.get(\"spoof_attempt\", datetime.min)).seconds > 60:\n",
    "                                self.mark_attendance(\"Spoof Attempt\", \"Spoofed\")\n",
    "                                self.recently_recognized[\"spoof_attempt\"] = datetime.now()\n",
    "                                self.root.after(0, self.update_attendance_display)\n",
    "                        \n",
    "                        # Draw on frame (for next display update)\n",
    "                        cv2.rectangle(frame, (x, y), (x+w, y+h), color, 2)\n",
    "                        cv2.putText(frame, label, (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)\n",
    "                    \n",
    "                    # Clean up recently recognized dictionary\n",
    "                    current_time = datetime.now()\n",
    "                    self.recently_recognized = {k: v for k, v in self.recently_recognized.items() \n",
    "                                             if current_time - v < timedelta(minutes=5)}\n",
    "                \n",
    "                except Exception as e:\n",
    "                    print(f\"Processing error: {e}\")\n",
    "                \n",
    "                time.sleep(0.1)  # Reduce CPU usage\n",
    "    \n",
    "    def extract_face_encodings(self, face_img):\n",
    "        \"\"\"Extract 128D face encodings\"\"\"\n",
    "        try:\n",
    "            rgb_face = cv2.cvtColor(face_img, cv2.COLOR_BGR2RGB)\n",
    "            encodings = face_encodings(rgb_face)\n",
    "            return encodings[0] if encodings else None\n",
    "        except Exception as e:\n",
    "            print(f\"Encoding error: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def recognize_face(self, face_encoding):\n",
    "        \"\"\"Compare face with known encodings\"\"\"\n",
    "        try:\n",
    "            distances = face_distance(self.known_encodings, face_encoding)\n",
    "            best_match_idx = np.argmin(distances)\n",
    "            min_distance = distances[best_match_idx]\n",
    "            \n",
    "            if min_distance <= self.RECOGNITION_THRESHOLD:\n",
    "                return self.known_names[best_match_idx], 1 - min_distance\n",
    "            return None, None\n",
    "        except Exception as e:\n",
    "            print(f\"Recognition error: {e}\")\n",
    "            return None, None\n",
    "    \n",
    "    def can_mark_attendance(self, name):\n",
    "        \"\"\"Check if attendance can be marked (not marked in last hour)\"\"\"\n",
    "        if not hasattr(self, 'attendance_df'):\n",
    "            return False\n",
    "        \n",
    "        now = datetime.now()\n",
    "        last_attendance = self.attendance_df[self.attendance_df['name'] == name]\n",
    "        \n",
    "        if not last_attendance.empty:\n",
    "            last_time = pd.to_datetime(last_attendance['timestamp'].iloc[-1])\n",
    "            return now - last_time >= self.ATTENDANCE_INTERVAL\n",
    "        return True\n",
    "    \n",
    "    def mark_attendance(self, name, status):\n",
    "        \"\"\"Mark attendance in the dataframe\"\"\"\n",
    "        now = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "        new_entry = pd.DataFrame([[name, now, status, self.current_subject]], \n",
    "                               columns=['name', 'timestamp', 'status', 'subject'])\n",
    "        self.attendance_df = pd.concat([self.attendance_df, new_entry], ignore_index=True)\n",
    "        \n",
    "        # Save to file\n",
    "        try:\n",
    "            self.attendance_df.to_csv(self.ATTENDANCE_FILE, index=False)\n",
    "        except Exception as e:\n",
    "            self.update_status(f\"Error saving attendance: {str(e)}\", \"error\")\n",
    "    \n",
    "    def update_attendance_display(self):\n",
    "        \"\"\"Update the attendance display in the GUI\"\"\"\n",
    "        if not hasattr(self, 'attendance_df'):\n",
    "            return\n",
    "        \n",
    "        # Update treeview\n",
    "        self.tree.delete(*self.tree.get_children())\n",
    "        \n",
    "        # Show today's records\n",
    "        today = datetime.now().date()\n",
    "        today_records = self.attendance_df[\n",
    "            pd.to_datetime(self.attendance_df['timestamp']).dt.date == today\n",
    "        ]\n",
    "        \n",
    "        for _, row in today_records.iterrows():\n",
    "            self.tree.insert('', tk.END, values=(\n",
    "                row['name'],\n",
    "                row['timestamp'],\n",
    "                row['status'],\n",
    "                row.get('subject', 'N/A')\n",
    "            ))\n",
    "        \n",
    "        # Update summary\n",
    "        present_count = len(today_records[today_records['status'] == 'Present'])\n",
    "        unique_students = today_records[today_records['status'] == 'Present']['name'].nunique()\n",
    "        self.summary_label.config(\n",
    "            text=f\"Today's attendance: {present_count} records\\n{unique_students} unique students\"\n",
    "        )\n",
    "    \n",
    "    def export_attendance(self):\n",
    "        \"\"\"Export attendance data to file\"\"\"\n",
    "        if self.attendance_df.empty:\n",
    "            messagebox.showwarning(\"Warning\", \"No attendance data to export!\")\n",
    "            return\n",
    "        \n",
    "        file_path = filedialog.asksaveasfilename(\n",
    "            defaultextension=\".csv\",\n",
    "            filetypes=[(\"CSV files\", \"*.csv\"), (\"Excel files\", \"*.xlsx\"), (\"All files\", \"*.*\")],\n",
    "            title=\"Save attendance data\"\n",
    "        )\n",
    "        \n",
    "        if file_path:\n",
    "            try:\n",
    "                if file_path.endswith('.xlsx'):\n",
    "                    self.attendance_df.to_excel(file_path, index=False)\n",
    "                else:\n",
    "                    self.attendance_df.to_csv(file_path, index=False)\n",
    "                self.update_status(f\"Attendance data exported to {file_path}\")\n",
    "            except Exception as e:\n",
    "                messagebox.showerror(\"Error\", f\"Failed to export data: {str(e)}\")\n",
    "    \n",
    "    def update_status(self, message, level=\"info\"):\n",
    "        \"\"\"Update the status label with a message\"\"\"\n",
    "        colors = {\n",
    "            \"info\": \"black\",\n",
    "            \"warning\": \"orange\",\n",
    "            \"error\": \"red\",\n",
    "            \"success\": \"green\"\n",
    "        }\n",
    "        self.status_label.config(text=message, foreground=colors.get(level, \"black\"))\n",
    "        print(f\"[{level.upper()}] {message}\")\n",
    "    \n",
    "    def on_close(self):\n",
    "        \"\"\"Clean up before closing\"\"\"\n",
    "        self.running = False\n",
    "        if hasattr(self, 'camera') and self.camera is not None:\n",
    "            self.camera.release()\n",
    "        self.root.destroy()\n",
    "    \n",
    "    def run(self):\n",
    "        \"\"\"Run the application\"\"\"\n",
    "        self.root.mainloop()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app = AttendanceSystem()\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import ttk, messagebox, filedialog\n",
    "from PIL import Image, ImageTk\n",
    "import cv2\n",
    "import threading\n",
    "import queue\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from deepface import DeepFace\n",
    "from face_recognition import face_encodings, face_distance\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "from tkcalendar import Calendar\n",
    "\n",
    "#  Color Theme\n",
    "BG_COLOR = \"#2E3440\"  # Dark slate\n",
    "PRIMARY_COLOR = \"#5E81AC\"  # Soft blue\n",
    "SECONDARY_COLOR = \"#88C0D0\"  # Light blue\n",
    "ACCENT_COLOR = \"#A3BE8C\"  # Green\n",
    "ERROR_COLOR = \"#BF616A\"  # Red\n",
    "TEXT_COLOR = \"#ECEFF4\"  # White\n",
    "\n",
    "class SmartAttendanceSystem:\n",
    "    def __init__(self, root):\n",
    "        self.root = root\n",
    "        self.root.title(\" Smart Attendance System\")\n",
    "        self.root.geometry(\"1280x800\")\n",
    "        self.root.configure(bg=BG_COLOR)\n",
    "        \n",
    "        #  Face Recognition Config\n",
    "        self.ENCODINGS_FILE = 'data/encodings.pkl'\n",
    "        self.ATTENDANCE_FILE = 'data/attendance.csv'\n",
    "        self.TIMETABLE_FILE = 'data/timetable.csv'\n",
    "        self.SPOOF_THRESHOLD = 0.7\n",
    "        self.RECOGNITION_THRESHOLD = 0.5\n",
    "        self.DETECTOR_BACKEND = \"opencv\"\n",
    "        \n",
    "        #  System State\n",
    "        self.running = False\n",
    "        self.camera = None\n",
    "        self.known_encodings = []\n",
    "        self.known_names = []\n",
    "        self.attendance_df = pd.DataFrame()\n",
    "        self.timetable_df = pd.DataFrame()\n",
    "        self.current_subject = None\n",
    "        self.current_class = None\n",
    "        self.recently_recognized = {}\n",
    "        \n",
    "        #  Camera Setup\n",
    "        self.camera_queue = queue.Queue(maxsize=1)\n",
    "        self.setup_camera()\n",
    "        \n",
    "        #  GUI Setup\n",
    "        self.setup_gui()\n",
    "        \n",
    "        #  Load Data\n",
    "        self.load_data()\n",
    "        \n",
    "        #  Auto-Detect Current Class/Subject\n",
    "        self.update_current_session()\n",
    "        \n",
    "    def setup_camera(self):\n",
    "        \"\"\"Initialize camera in a separate thread\"\"\"\n",
    "        self.camera = cv2.VideoCapture(0)\n",
    "        if not self.camera.isOpened():\n",
    "            messagebox.showerror(\"Error\", \"Camera not detected!\")\n",
    "            return\n",
    "        \n",
    "        self.camera_thread = threading.Thread(target=self._camera_loop, daemon=True)\n",
    "        self.camera_thread.start()\n",
    "    \n",
    "    def _camera_loop(self):\n",
    "        \"\"\"Thread for capturing frames\"\"\"\n",
    "        while True:\n",
    "            ret, frame = self.camera.read()\n",
    "            if ret:\n",
    "                frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                frame_resized = cv2.resize(frame_rgb, (640, 480))\n",
    "                \n",
    "                if self.camera_queue.full():\n",
    "                    self.camera_queue.get_nowait()\n",
    "                self.camera_queue.put(frame_resized)\n",
    "            time.sleep(0.03)  # ~30 FPS\n",
    "    \n",
    "    def setup_gui(self):\n",
    "        \"\"\"Build the modern GUI\"\"\"\n",
    "        #  Main Frame\n",
    "        main_frame = tk.Frame(self.root, bg=BG_COLOR)\n",
    "        main_frame.pack(fill=tk.BOTH, expand=True, padx=10, pady=10)\n",
    "        \n",
    "        #  Left Panel (Camera + Controls)\n",
    "        left_panel = tk.Frame(main_frame, bg=BG_COLOR)\n",
    "        left_panel.pack(side=tk.LEFT, fill=tk.BOTH, expand=True)\n",
    "        \n",
    "        #  Camera Frame\n",
    "        camera_frame = tk.LabelFrame(left_panel, text=\" Live Camera\", font=(\"Helvetica\", 12, \"bold\"), bg=BG_COLOR, fg=TEXT_COLOR)\n",
    "        camera_frame.pack(fill=tk.BOTH, expand=True, padx=5, pady=5)\n",
    "        \n",
    "        self.camera_label = tk.Label(camera_frame, bg=\"black\")\n",
    "        self.camera_label.pack(fill=tk.BOTH, expand=True)\n",
    "        \n",
    "        #  Controls Frame\n",
    "        controls_frame = tk.Frame(left_panel, bg=BG_COLOR)\n",
    "        controls_frame.pack(fill=tk.X, padx=5, pady=5)\n",
    "        \n",
    "        self.start_btn = tk.Button(\n",
    "            controls_frame, text=\" START\", font=(\"Helvetica\", 10, \"bold\"),\n",
    "            bg=ACCENT_COLOR, fg=\"white\", relief=tk.FLAT,\n",
    "            command=self.start_recognition\n",
    "        )\n",
    "        self.start_btn.pack(side=tk.LEFT, padx=5)\n",
    "        \n",
    "        self.stop_btn = tk.Button(\n",
    "            controls_frame, text=\" STOP\", font=(\"Helvetica\", 10, \"bold\"),\n",
    "            bg=ERROR_COLOR, fg=\"white\", relief=tk.FLAT,\n",
    "            command=self.stop_recognition, state=tk.DISABLED\n",
    "        )\n",
    "        self.stop_btn.pack(side=tk.LEFT, padx=5)\n",
    "        \n",
    "        self.export_btn = tk.Button(\n",
    "            controls_frame, text=\" EXPORT\", font=(\"Helvetica\", 10, \"bold\"),\n",
    "            bg=PRIMARY_COLOR, fg=\"white\", relief=tk.FLAT,\n",
    "            command=self.export_attendance\n",
    "        )\n",
    "        self.export_btn.pack(side=tk.RIGHT, padx=5)\n",
    "        \n",
    "        #  Right Panel (Attendance Dashboard)\n",
    "        right_panel = tk.Frame(main_frame, bg=BG_COLOR, width=400)\n",
    "        right_panel.pack(side=tk.RIGHT, fill=tk.BOTH)\n",
    "        \n",
    "        #  Current Session Info\n",
    "        session_frame = tk.LabelFrame(right_panel, text=\" Current Session\", font=(\"Helvetica\", 12, \"bold\"), bg=BG_COLOR, fg=TEXT_COLOR)\n",
    "        session_frame.pack(fill=tk.X, padx=5, pady=5)\n",
    "        \n",
    "        self.class_label = tk.Label(session_frame, text=\"Class: N/A\", font=(\"Helvetica\", 10), bg=BG_COLOR, fg=TEXT_COLOR)\n",
    "        self.class_label.pack(anchor=tk.W, padx=5, pady=2)\n",
    "        \n",
    "        self.subject_label = tk.Label(session_frame, text=\"Subject: N/A\", font=(\"Helvetica\", 10), bg=BG_COLOR, fg=TEXT_COLOR)\n",
    "        self.subject_label.pack(anchor=tk.W, padx=5, pady=2)\n",
    "        \n",
    "        self.time_label = tk.Label(session_frame, text=\"Time: N/A\", font=(\"Helvetica\", 10), bg=BG_COLOR, fg=TEXT_COLOR)\n",
    "        self.time_label.pack(anchor=tk.W, padx=5, pady=2)\n",
    "        \n",
    "        #  Attendance Summary\n",
    "        summary_frame = tk.LabelFrame(right_panel, text=\" Today's Stats\", font=(\"Helvetica\", 12, \"bold\"), bg=BG_COLOR, fg=TEXT_COLOR)\n",
    "        summary_frame.pack(fill=tk.X, padx=5, pady=5)\n",
    "        \n",
    "        self.summary_label = tk.Label(summary_frame, text=\"No attendance today\", font=(\"Helvetica\", 10), bg=BG_COLOR, fg=TEXT_COLOR)\n",
    "        self.summary_label.pack(fill=tk.X, padx=5, pady=5)\n",
    "        \n",
    "        #  Attendance Logs\n",
    "        log_frame = tk.LabelFrame(right_panel, text=\" Attendance Logs\", font=(\"Helvetica\", 12, \"bold\"), bg=BG_COLOR, fg=TEXT_COLOR)\n",
    "        log_frame.pack(fill=tk.BOTH, expand=True, padx=5, pady=5)\n",
    "        \n",
    "        #  Treeview (Attendance Table)\n",
    "        style = ttk.Style()\n",
    "        style.configure(\"Treeview\", background=BG_COLOR, foreground=TEXT_COLOR, fieldbackground=BG_COLOR)\n",
    "        style.map(\"Treeview\", background=[('selected', PRIMARY_COLOR)])\n",
    "        \n",
    "        self.tree = ttk.Treeview(log_frame, columns=(\"Name\", \"Time\", \"Status\", \"Subject\"), show=\"headings\")\n",
    "        self.tree.heading(\"Name\", text=\"Name\")\n",
    "        self.tree.heading(\"Time\", text=\"Time\")\n",
    "        self.tree.heading(\"Status\", text=\"Status\")\n",
    "        self.tree.heading(\"Subject\", text=\"Subject\")\n",
    "        \n",
    "        scrollbar = ttk.Scrollbar(log_frame, orient=tk.VERTICAL, command=self.tree.yview)\n",
    "        self.tree.configure(yscroll=scrollbar.set)\n",
    "        scrollbar.pack(side=tk.RIGHT, fill=tk.Y)\n",
    "        self.tree.pack(fill=tk.BOTH, expand=True)\n",
    "        \n",
    "        #  Update Clock\n",
    "        self.update_clock()\n",
    "    \n",
    "    def update_clock(self):\n",
    "        \"\"\"Live clock in GUI\"\"\"\n",
    "        now = datetime.now().strftime(\"%H:%M:%S\")\n",
    "        self.time_label.config(text=f\"Time: {now}\")\n",
    "        self.root.after(1000, self.update_clock)\n",
    "    \n",
    "    def load_data(self):\n",
    "        \"\"\"Load encodings, timetable, and attendance\"\"\"\n",
    "        try:\n",
    "            #  Load face encodings\n",
    "            if os.path.exists(self.ENCODINGS_FILE):\n",
    "                with open(self.ENCODINGS_FILE, 'rb') as f:\n",
    "                    data = pickle.load(f)\n",
    "                self.known_encodings = data['encodings']\n",
    "                self.known_names = data['names']\n",
    "            \n",
    "            #  Load timetable\n",
    "            if os.path.exists(self.TIMETABLE_FILE):\n",
    "                self.timetable_df = pd.read_csv(self.TIMETABLE_FILE)\n",
    "            \n",
    "            #  Load attendance\n",
    "            if os.path.exists(self.ATTENDANCE_FILE):\n",
    "                self.attendance_df = pd.read_csv(self.ATTENDANCE_FILE, parse_dates=['timestamp'])\n",
    "            else:\n",
    "                self.attendance_df = pd.DataFrame(columns=['name', 'timestamp', 'status', 'subject'])\n",
    "            \n",
    "            self.update_attendance_display()\n",
    "        except Exception as e:\n",
    "            messagebox.showerror(\"Error\", f\"Failed to load data: {str(e)}\")\n",
    "    \n",
    "    def update_current_session(self):\n",
    "        \"\"\"Auto-detect current class/subject based on time\"\"\"\n",
    "        if self.timetable_df.empty:\n",
    "            return\n",
    "        \n",
    "        now = datetime.now()\n",
    "        current_time = now.strftime(\"%H:%M\")\n",
    "        current_day = now.strftime(\"%A\")\n",
    "        \n",
    "        # Filter timetable for current day and time\n",
    "        active_sessions = self.timetable_df[\n",
    "            (self.timetable_df['day'] == current_day) &\n",
    "            (self.timetable_df['time'].str.contains(current_time))\n",
    "        ]\n",
    "        \n",
    "        if not active_sessions.empty:\n",
    "            self.current_class = active_sessions.iloc[0]['class']\n",
    "            self.current_subject = active_sessions.iloc[0]['subject']\n",
    "            \n",
    "            self.class_label.config(text=f\"Class: {self.current_class}\")\n",
    "            self.subject_label.config(text=f\"Subject: {self.current_subject}\")\n",
    "    \n",
    "    def start_recognition(self):\n",
    "        \"\"\"Start face recognition\"\"\"\n",
    "        if not self.known_encodings:\n",
    "            messagebox.showerror(\"Error\", \"No face data loaded!\")\n",
    "            return\n",
    "        \n",
    "        self.running = True\n",
    "        self.start_btn.config(state=tk.DISABLED)\n",
    "        self.stop_btn.config(state=tk.NORMAL)\n",
    "        \n",
    "        # Start processing thread\n",
    "        self.processing_thread = threading.Thread(target=self._process_faces, daemon=True)\n",
    "        self.processing_thread.start()\n",
    "        \n",
    "        # Start camera updates\n",
    "        self.update_camera_display()\n",
    "    \n",
    "    def stop_recognition(self):\n",
    "        \"\"\"Stop face recognition\"\"\"\n",
    "        self.running = False\n",
    "        self.start_btn.config(state=tk.NORMAL)\n",
    "        self.stop_btn.config(state=tk.DISABLED)\n",
    "    \n",
    "    def _process_faces(self):\n",
    "        \"\"\"Face recognition thread\"\"\"\n",
    "        while self.running:\n",
    "            if not self.camera_queue.empty():\n",
    "                frame = self.camera_queue.get()\n",
    "                frame_bgr = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "                \n",
    "                try:\n",
    "                    # Detect faces with anti-spoofing\n",
    "                    face_objs = DeepFace.extract_faces(\n",
    "                        img_path=frame_bgr,\n",
    "                        detector_backend=self.DETECTOR_BACKEND,\n",
    "                        anti_spoofing=True,\n",
    "                        enforce_detection=False\n",
    "                    )\n",
    "                    \n",
    "                    for face_obj in face_objs:\n",
    "                        x, y, w, h = face_obj[\"facial_area\"][\"x\"], face_obj[\"facial_area\"][\"y\"], \\\n",
    "                                     face_obj[\"facial_area\"][\"w\"], face_obj[\"facial_area\"][\"h\"]\n",
    "                        \n",
    "                        # Check if face is real\n",
    "                        is_real = face_obj[\"is_real\"] and (face_obj[\"antispoof_score\"] >= self.SPOOF_THRESHOLD)\n",
    "                        \n",
    "                        if is_real:\n",
    "                            # Extract face encoding\n",
    "                            face_roi = frame_bgr[y:y+h, x:x+w]\n",
    "                            face_encoding = self._extract_encoding(face_roi)\n",
    "                            \n",
    "                            if face_encoding is not None:\n",
    "                                # Recognize face\n",
    "                                name, confidence = self._recognize_face(face_encoding)\n",
    "                                \n",
    "                                # Mark attendance if new detection\n",
    "                                if name and name not in self.recently_recognized:\n",
    "                                    self.mark_attendance(name, \"Present\")\n",
    "                                    self.recently_recognized[name] = datetime.now()\n",
    "                                    self.root.after(0, self.update_attendance_display)\n",
    "                except Exception as e:\n",
    "                    print(f\"Face processing error: {e}\")\n",
    "    \n",
    "    def mark_attendance(self, name, status):\n",
    "        \"\"\"Log attendance with timestamp\"\"\"\n",
    "        now = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        new_entry = pd.DataFrame([[name, now, status, self.current_subject]], \n",
    "                               columns=['name', 'timestamp', 'status', 'subject'])\n",
    "        self.attendance_df = pd.concat([self.attendance_df, new_entry], ignore_index=True)\n",
    "        self.attendance_df.to_csv(self.ATTENDANCE_FILE, index=False)\n",
    "    \n",
    "    def update_attendance_display(self):\n",
    "        \"\"\"Update the attendance dashboard\"\"\"\n",
    "        self.tree.delete(*self.tree.get_children())\n",
    "        \n",
    "        today = datetime.now().date()\n",
    "        today_records = self.attendance_df[\n",
    "            pd.to_datetime(self.attendance_df['timestamp']).dt.date == today\n",
    "        ]\n",
    "        \n",
    "        for _, row in today_records.iterrows():\n",
    "            self.tree.insert(\"\", tk.END, values=(\n",
    "                row['name'],\n",
    "                row['timestamp'],\n",
    "                row['status'],\n",
    "                row['subject']\n",
    "            ))\n",
    "        \n",
    "        # Update summary\n",
    "        present_count = len(today_records[today_records['status'] == 'Present'])\n",
    "        unique_students = today_records[today_records['status'] == 'Present']['name'].nunique()\n",
    "        self.summary_label.config(\n",
    "            text=f\" Today's Attendance\\n Present: {unique_students} students\\n Total Records: {present_count}\"\n",
    "        )\n",
    "    \n",
    "    def update_camera_display(self):\n",
    "        \"\"\"Update camera feed in GUI\"\"\"\n",
    "        if not self.camera_queue.empty():\n",
    "            frame = self.camera_queue.get()\n",
    "            img = Image.fromarray(frame)\n",
    "            imgtk = ImageTk.PhotoImage(image=img)\n",
    "            \n",
    "            self.camera_label.imgtk = imgtk\n",
    "            self.camera_label.configure(image=imgtk)\n",
    "        \n",
    "        if self.running:\n",
    "            self.root.after(30, self.update_camera_display)\n",
    "    \n",
    "    def export_attendance(self):\n",
    "        \"\"\"Export attendance to CSV/Excel\"\"\"\n",
    "        if self.attendance_df.empty:\n",
    "            messagebox.showwarning(\"Warning\", \"No attendance data to export!\")\n",
    "            return\n",
    "        \n",
    "        file_path = filedialog.asksaveasfilename(\n",
    "            defaultextension=\".csv\",\n",
    "            filetypes=[(\"CSV\", \"*.csv\"), (\"Excel\", \"*.xlsx\")],\n",
    "            title=\"Save Attendance Report\"\n",
    "        )\n",
    "        \n",
    "        if file_path:\n",
    "            try:\n",
    "                if file_path.endswith(\".xlsx\"):\n",
    "                    self.attendance_df.to_excel(file_path, index=False)\n",
    "                else:\n",
    "                    self.attendance_df.to_csv(file_path, index=False)\n",
    "                messagebox.showinfo(\"Success\", f\"Attendance exported to:\\n{file_path}\")\n",
    "            except Exception as e:\n",
    "                messagebox.showerror(\"Error\", f\"Export failed: {str(e)}\")\n",
    "    \n",
    "    def on_close(self):\n",
    "        \"\"\"Cleanup before closing\"\"\"\n",
    "        self.running = False\n",
    "        if self.camera:\n",
    "            self.camera.release()\n",
    "        self.root.destroy()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    root = tk.Tk()\n",
    "    app = SmartAttendanceSystem(root)\n",
    "    root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-3:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\suryansh\\anaconda3\\envs\\face_recognition_env\\lib\\threading.py\", line 932, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\Users\\suryansh\\anaconda3\\envs\\face_recognition_env\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 766, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"c:\\Users\\suryansh\\anaconda3\\envs\\face_recognition_env\\lib\\threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\suryansh\\AppData\\Local\\Temp\\ipykernel_19468\\4264188998.py\", line 109, in _camera_loop\n",
      "NameError: name 'time' is not defined\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'start_time'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\suryansh\\anaconda3\\envs\\face_recognition_env\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3653\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3652\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\suryansh\\anaconda3\\envs\\face_recognition_env\\lib\\site-packages\\pandas\\_libs\\index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\suryansh\\anaconda3\\envs\\face_recognition_env\\lib\\site-packages\\pandas\\_libs\\index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'start_time'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 465\u001b[0m\n\u001b[0;32m    463\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    464\u001b[0m     root \u001b[38;5;241m=\u001b[39m tk\u001b[38;5;241m.\u001b[39mTk()\n\u001b[1;32m--> 465\u001b[0m     app \u001b[38;5;241m=\u001b[39m \u001b[43mSmartAttendanceSystem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    466\u001b[0m     root\u001b[38;5;241m.\u001b[39mmainloop()\n",
      "Cell \u001b[1;32mIn[3], line 68\u001b[0m, in \u001b[0;36mSmartAttendanceSystem.__init__\u001b[1;34m(self, root)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_data()\n\u001b[0;32m     67\u001b[0m \u001b[38;5;66;03m#  Auto-Detect Current Class/Subject\u001b[39;00m\n\u001b[1;32m---> 68\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate_current_session\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;66;03m#  Start camera display\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate_camera_display()\n",
      "Cell \u001b[1;32mIn[3], line 355\u001b[0m, in \u001b[0;36mSmartAttendanceSystem.update_current_session\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    350\u001b[0m current_day \u001b[38;5;241m=\u001b[39m now\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mA\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    352\u001b[0m \u001b[38;5;66;03m# Filter timetable for current day and time\u001b[39;00m\n\u001b[0;32m    353\u001b[0m active_sessions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimetable_df[\n\u001b[0;32m    354\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimetable_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mday\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m current_day) \u001b[38;5;241m&\u001b[39m\n\u001b[1;32m--> 355\u001b[0m     (\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimetable_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstart_time\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m current_time) \u001b[38;5;241m&\u001b[39m\n\u001b[0;32m    356\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimetable_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mend_time\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m current_time)\n\u001b[0;32m    357\u001b[0m ]\n\u001b[0;32m    359\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m active_sessions\u001b[38;5;241m.\u001b[39mempty:\n\u001b[0;32m    360\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_class \u001b[38;5;241m=\u001b[39m active_sessions\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclass\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\suryansh\\anaconda3\\envs\\face_recognition_env\\lib\\site-packages\\pandas\\core\\frame.py:3761\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3760\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3761\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3762\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3763\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\suryansh\\anaconda3\\envs\\face_recognition_env\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3655\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3655\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3656\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3657\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3658\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3659\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3660\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'start_time'"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import ttk, messagebox, filedialog\n",
    "from PIL import Image, ImageTk\n",
    "import cv2\n",
    "import threading\n",
    "import queue\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "from deepface import DeepFace\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "#  Color Theme\n",
    "BG_COLOR = \"#2E3440\"  # Dark slate\n",
    "PRIMARY_COLOR = \"#5E81AC\"  # Soft blue\n",
    "SECONDARY_COLOR = \"#88C0D0\"  # Light blue\n",
    "ACCENT_COLOR = \"#A3BE8C\"  # Green\n",
    "ERROR_COLOR = \"#BF616A\"  # Red\n",
    "TEXT_COLOR = \"#ECEFF4\"  # White\n",
    "\n",
    "class SmartAttendanceSystem:\n",
    "    def __init__(self, root):\n",
    "        self.root = root\n",
    "        self.root.title(\" Smart Attendance System\")\n",
    "        self.root.geometry(\"1280x800\")\n",
    "        self.root.configure(bg=BG_COLOR)\n",
    "        \n",
    "        #  Face Recognition Config\n",
    "        self.ENCODINGS_FILE = 'data/encodings.pkl'\n",
    "        self.ATTENDANCE_FILE = 'data/attendance.csv'\n",
    "        self.TIMETABLE_FILE = 'data/timetable.csv'\n",
    "        self.SPOOF_THRESHOLD = 0.7\n",
    "        self.RECOGNITION_THRESHOLD = 0.6\n",
    "        self.DETECTOR_BACKEND = \"opencv\"\n",
    "        self.MIN_FACE_SIZE = 100  # Minimum face size in pixels\n",
    "        \n",
    "        #  System State\n",
    "        self.running = False\n",
    "        self.camera = None\n",
    "        self.known_encodings = []\n",
    "        self.known_names = []\n",
    "        self.attendance_df = pd.DataFrame()\n",
    "        self.timetable_df = pd.DataFrame()\n",
    "        self.current_subject = \"General\"\n",
    "        self.current_class = \"Default\"\n",
    "        self.recently_recognized = {}\n",
    "        self.last_processed_time = 0\n",
    "        self.processing_interval = 1.0  # Process frames every 1 second\n",
    "        \n",
    "        #  Camera Setup\n",
    "        self.camera_queue = queue.Queue(maxsize=1)\n",
    "        self.processed_frame_queue = queue.Queue(maxsize=1)\n",
    "        self.setup_camera()\n",
    "        \n",
    "        #  Thread Management\n",
    "        self.executor = ThreadPoolExecutor(max_workers=4)\n",
    "        self.face_detection_active = False\n",
    "        \n",
    "        #  GUI Setup\n",
    "        self.setup_gui()\n",
    "        \n",
    "        #  Load Data\n",
    "        self.load_data()\n",
    "        \n",
    "        #  Auto-Detect Current Class/Subject\n",
    "        self.update_current_session()\n",
    "        \n",
    "        #  Start camera display\n",
    "        self.update_camera_display()\n",
    "        \n",
    "        #  Cleanup on window close\n",
    "        self.root.protocol(\"WM_DELETE_WINDOW\", self.on_close)\n",
    "    \n",
    "    def setup_camera(self):\n",
    "        \"\"\"Initialize camera with optimized settings\"\"\"\n",
    "        self.camera = cv2.VideoCapture(0)\n",
    "        if not self.camera.isOpened():\n",
    "            messagebox.showerror(\"Error\", \"Camera not detected!\")\n",
    "            return\n",
    "        \n",
    "        # Set camera resolution to 640x480 for better performance\n",
    "        self.camera.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "        self.camera.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "        \n",
    "        # Start camera thread\n",
    "        self.camera_thread = threading.Thread(target=self._camera_loop, daemon=True)\n",
    "        self.camera_thread.start()\n",
    "    \n",
    "    def _camera_loop(self):\n",
    "        \"\"\"Thread for capturing frames with optimized frame skipping\"\"\"\n",
    "        while True:\n",
    "            ret, frame = self.camera.read()\n",
    "            if ret:\n",
    "                frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                \n",
    "                # Put frame in queue for display\n",
    "                if self.camera_queue.full():\n",
    "                    self.camera_queue.get_nowait()\n",
    "                self.camera_queue.put(frame_rgb)\n",
    "                \n",
    "                # Put frame in processing queue if recognition is active\n",
    "                if self.running and not self.face_detection_active:\n",
    "                    self.face_detection_active = True\n",
    "                    self.executor.submit(self._process_frame, frame_rgb.copy())\n",
    "            \n",
    "            # Control frame rate\n",
    "            time.sleep(0.03)  # ~30 FPS\n",
    "    \n",
    "    def _process_frame(self, frame):\n",
    "        \"\"\"Process a single frame for face detection and recognition\"\"\"\n",
    "        try:\n",
    "            current_time = time.time()\n",
    "            \n",
    "            # Skip processing if not enough time has passed\n",
    "            if current_time - self.last_processed_time < self.processing_interval:\n",
    "                self.face_detection_active = False\n",
    "                return\n",
    "            \n",
    "            self.last_processed_time = current_time\n",
    "            \n",
    "            # Detect faces with anti-spoofing\n",
    "            face_objs = DeepFace.extract_faces(\n",
    "                img_path=frame,\n",
    "                detector_backend=self.DETECTOR_BACKEND,\n",
    "                anti_spoofing=True,\n",
    "                enforce_detection=False\n",
    "            )\n",
    "            \n",
    "            processed_frame = frame.copy()\n",
    "            \n",
    "            for face_obj in face_objs:\n",
    "                x, y, w, h = face_obj[\"facial_area\"][\"x\"], face_obj[\"facial_area\"][\"y\"], \\\n",
    "                             face_obj[\"facial_area\"][\"w\"], face_obj[\"facial_area\"][\"h\"]\n",
    "                \n",
    "                # Skip small faces\n",
    "                if w < self.MIN_FACE_SIZE or h < self.MIN_FACE_SIZE:\n",
    "                    continue\n",
    "                \n",
    "                # Check if face is real\n",
    "                is_real = face_obj.get(\"is_real\", True) and (face_obj.get(\"antispoof_score\", 1.0) >= self.SPOOF_THRESHOLD)\n",
    "                \n",
    "                if is_real:\n",
    "                    # Extract face ROI\n",
    "                    face_roi = frame[y:y+h, x:x+w]\n",
    "                    \n",
    "                    # Recognize face\n",
    "                    name, confidence = self._recognize_face(face_roi)\n",
    "                    \n",
    "                    # Draw rectangle and label\n",
    "                    color = (0, 255, 0) if name else (0, 0, 255)\n",
    "                    cv2.rectangle(processed_frame, (x, y), (x+w, y+h), color, 2)\n",
    "                    \n",
    "                    if name:\n",
    "                        label = f\"{name} ({confidence:.2f})\"\n",
    "                        cv2.putText(processed_frame, label, (x, y-10), \n",
    "                                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "                        \n",
    "                        # Mark attendance if new detection\n",
    "                        if name not in self.recently_recognized:\n",
    "                            self.mark_attendance(name, \"Present\")\n",
    "                            self.recently_recognized[name] = datetime.now()\n",
    "                            self.root.after(0, self.update_attendance_display)\n",
    "            \n",
    "            # Put processed frame in queue for display\n",
    "            if self.processed_frame_queue.full():\n",
    "                self.processed_frame_queue.get_nowait()\n",
    "            self.processed_frame_queue.put(processed_frame)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Face processing error: {e}\")\n",
    "        finally:\n",
    "            self.face_detection_active = False\n",
    "    \n",
    "    def _recognize_face(self, face_img):\n",
    "        \"\"\"Recognize face using DeepFace with fallback to encodings\"\"\"\n",
    "        try:\n",
    "            # First try DeepFace recognition\n",
    "            result = DeepFace.find(\n",
    "                img_path=face_img,\n",
    "                db_path=\"data/faces\",\n",
    "                enforce_detection=False,\n",
    "                silent=True\n",
    "            )\n",
    "            \n",
    "            if result and len(result) > 0 and len(result[0]) > 0:\n",
    "                best_match = result[0].iloc[0]\n",
    "                if best_match['distance'] < self.RECOGNITION_THRESHOLD:\n",
    "                    name = os.path.basename(os.path.dirname(best_match['identity']))\n",
    "                    return name, 1 - best_match['distance']\n",
    "            \n",
    "            # Fallback to encodings if DeepFace fails\n",
    "            if self.known_encodings:\n",
    "                face_encoding = DeepFace.represent(\n",
    "                    img_path=face_img,\n",
    "                    model_name=\"Facenet\",\n",
    "                    enforce_detection=False\n",
    "                )\n",
    "                \n",
    "                if face_encoding:\n",
    "                    face_encoding = np.array(face_encoding)\n",
    "                    distances = np.linalg.norm(self.known_encodings - face_encoding, axis=1)\n",
    "                    min_idx = np.argmin(distances)\n",
    "                    min_distance = distances[min_idx]\n",
    "                    \n",
    "                    if min_distance < self.RECOGNITION_THRESHOLD:\n",
    "                        return self.known_names[min_idx], 1 - min_distance\n",
    "            \n",
    "            return None, 0.0\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Recognition error: {e}\")\n",
    "            return None, 0.0\n",
    "    \n",
    "    def setup_gui(self):\n",
    "        \"\"\"Build the modern GUI\"\"\"\n",
    "        #  Main Frame\n",
    "        main_frame = tk.Frame(self.root, bg=BG_COLOR)\n",
    "        main_frame.pack(fill=tk.BOTH, expand=True, padx=10, pady=10)\n",
    "        \n",
    "        #  Left Panel (Camera + Controls)\n",
    "        left_panel = tk.Frame(main_frame, bg=BG_COLOR)\n",
    "        left_panel.pack(side=tk.LEFT, fill=tk.BOTH, expand=True)\n",
    "        \n",
    "        #  Camera Frame\n",
    "        camera_frame = tk.LabelFrame(left_panel, text=\" Live Camera\", font=(\"Helvetica\", 12, \"bold\"), \n",
    "                                   bg=BG_COLOR, fg=TEXT_COLOR)\n",
    "        camera_frame.pack(fill=tk.BOTH, expand=True, padx=5, pady=5)\n",
    "        \n",
    "        self.camera_label = tk.Label(camera_frame, bg=\"black\")\n",
    "        self.camera_label.pack(fill=tk.BOTH, expand=True)\n",
    "        \n",
    "        #  Controls Frame\n",
    "        controls_frame = tk.Frame(left_panel, bg=BG_COLOR)\n",
    "        controls_frame.pack(fill=tk.X, padx=5, pady=5)\n",
    "        \n",
    "        self.start_btn = tk.Button(\n",
    "            controls_frame, text=\" START RECOGNITION\", font=(\"Helvetica\", 10, \"bold\"),\n",
    "            bg=ACCENT_COLOR, fg=\"white\", relief=tk.FLAT,\n",
    "            command=self.start_recognition\n",
    "        )\n",
    "        self.start_btn.pack(side=tk.LEFT, padx=5)\n",
    "        \n",
    "        self.stop_btn = tk.Button(\n",
    "            controls_frame, text=\" STOP RECOGNITION\", font=(\"Helvetica\", 10, \"bold\"),\n",
    "            bg=ERROR_COLOR, fg=\"white\", relief=tk.FLAT,\n",
    "            command=self.stop_recognition, state=tk.DISABLED\n",
    "        )\n",
    "        self.stop_btn.pack(side=tk.LEFT, padx=5)\n",
    "        \n",
    "        self.export_btn = tk.Button(\n",
    "            controls_frame, text=\" EXPORT ATTENDANCE\", font=(\"Helvetica\", 10, \"bold\"),\n",
    "            bg=PRIMARY_COLOR, fg=\"white\", relief=tk.FLAT,\n",
    "            command=self.export_attendance\n",
    "        )\n",
    "        self.export_btn.pack(side=tk.RIGHT, padx=5)\n",
    "        \n",
    "        #  Right Panel (Attendance Dashboard)\n",
    "        right_panel = tk.Frame(main_frame, bg=BG_COLOR, width=400)\n",
    "        right_panel.pack(side=tk.RIGHT, fill=tk.BOTH)\n",
    "        \n",
    "        #  Current Session Info\n",
    "        session_frame = tk.LabelFrame(right_panel, text=\" Current Session\", \n",
    "                                     font=(\"Helvetica\", 12, \"bold\"), bg=BG_COLOR, fg=TEXT_COLOR)\n",
    "        session_frame.pack(fill=tk.X, padx=5, pady=5)\n",
    "        \n",
    "        self.class_label = tk.Label(session_frame, text=\"Class: Default\", \n",
    "                                  font=(\"Helvetica\", 10), bg=BG_COLOR, fg=TEXT_COLOR)\n",
    "        self.class_label.pack(anchor=tk.W, padx=5, pady=2)\n",
    "        \n",
    "        self.subject_label = tk.Label(session_frame, text=\"Subject: General\", \n",
    "                                    font=(\"Helvetica\", 10), bg=BG_COLOR, fg=TEXT_COLOR)\n",
    "        self.subject_label.pack(anchor=tk.W, padx=5, pady=2)\n",
    "        \n",
    "        self.time_label = tk.Label(session_frame, text=\"Time: --:--:--\", \n",
    "                                 font=(\"Helvetica\", 10), bg=BG_COLOR, fg=TEXT_COLOR)\n",
    "        self.time_label.pack(anchor=tk.W, padx=5, pady=2)\n",
    "        \n",
    "        #  Attendance Summary\n",
    "        summary_frame = tk.LabelFrame(right_panel, text=\" Today's Stats\", \n",
    "                                    font=(\"Helvetica\", 12, \"bold\"), bg=BG_COLOR, fg=TEXT_COLOR)\n",
    "        summary_frame.pack(fill=tk.X, padx=5, pady=5)\n",
    "        \n",
    "        self.summary_label = tk.Label(summary_frame, text=\"No attendance today\", \n",
    "                                    font=(\"Helvetica\", 10), bg=BG_COLOR, fg=TEXT_COLOR)\n",
    "        self.summary_label.pack(fill=tk.X, padx=5, pady=5)\n",
    "        \n",
    "        #  Attendance Logs\n",
    "        log_frame = tk.LabelFrame(right_panel, text=\" Attendance Logs\", \n",
    "                                font=(\"Helvetica\", 12, \"bold\"), bg=BG_COLOR, fg=TEXT_COLOR)\n",
    "        log_frame.pack(fill=tk.BOTH, expand=True, padx=5, pady=5)\n",
    "        \n",
    "        #  Treeview (Attendance Table)\n",
    "        style = ttk.Style()\n",
    "        style.configure(\"Treeview\", background=BG_COLOR, foreground=TEXT_COLOR, fieldbackground=BG_COLOR)\n",
    "        style.map(\"Treeview\", background=[('selected', PRIMARY_COLOR)])\n",
    "        \n",
    "        self.tree = ttk.Treeview(log_frame, columns=(\"Name\", \"Time\", \"Status\", \"Subject\"), show=\"headings\")\n",
    "        self.tree.heading(\"Name\", text=\"Name\")\n",
    "        self.tree.heading(\"Time\", text=\"Time\")\n",
    "        self.tree.heading(\"Status\", text=\"Status\")\n",
    "        self.tree.heading(\"Subject\", text=\"Subject\")\n",
    "        \n",
    "        scrollbar = ttk.Scrollbar(log_frame, orient=tk.VERTICAL, command=self.tree.yview)\n",
    "        self.tree.configure(yscroll=scrollbar.set)\n",
    "        scrollbar.pack(side=tk.RIGHT, fill=tk.Y)\n",
    "        self.tree.pack(fill=tk.BOTH, expand=True)\n",
    "        \n",
    "        #  Update Clock\n",
    "        self.update_clock()\n",
    "    \n",
    "    def update_clock(self):\n",
    "        \"\"\"Live clock in GUI\"\"\"\n",
    "        now = datetime.now().strftime(\"%H:%M:%S\")\n",
    "        self.time_label.config(text=f\"Time: {now}\")\n",
    "        self.root.after(1000, self.update_clock)\n",
    "    \n",
    "    def load_data(self):\n",
    "        \"\"\"Load encodings, timetable, and attendance\"\"\"\n",
    "        try:\n",
    "            #  Load face encodings\n",
    "            if os.path.exists(self.ENCODINGS_FILE):\n",
    "                with open(self.ENCODINGS_FILE, 'rb') as f:\n",
    "                    data = pickle.load(f)\n",
    "                self.known_encodings = data['encodings']\n",
    "                self.known_names = data['names']\n",
    "            \n",
    "            #  Load timetable\n",
    "            if os.path.exists(self.TIMETABLE_FILE):\n",
    "                self.timetable_df = pd.read_csv(self.TIMETABLE_FILE)\n",
    "            \n",
    "            #  Load attendance\n",
    "            if os.path.exists(self.ATTENDANCE_FILE):\n",
    "                self.attendance_df = pd.read_csv(self.ATTENDANCE_FILE)\n",
    "            else:\n",
    "                self.attendance_df = pd.DataFrame(columns=['name', 'timestamp', 'status', 'subject'])\n",
    "            \n",
    "            self.update_attendance_display()\n",
    "        except Exception as e:\n",
    "            messagebox.showerror(\"Error\", f\"Failed to load data: {str(e)}\")\n",
    "    \n",
    "    def update_current_session(self):\n",
    "        \"\"\"Auto-detect current class/subject based on time\"\"\"\n",
    "        if self.timetable_df.empty:\n",
    "            return\n",
    "        \n",
    "        now = datetime.now()\n",
    "        current_time = now.strftime(\"%H:%M\")\n",
    "        current_day = now.strftime(\"%A\")\n",
    "        \n",
    "        # Filter timetable for current day and time\n",
    "        active_sessions = self.timetable_df[\n",
    "            (self.timetable_df['day'] == current_day) &\n",
    "            (self.timetable_df['start_time'] <= current_time) &\n",
    "            (self.timetable_df['end_time'] >= current_time)\n",
    "        ]\n",
    "        \n",
    "        if not active_sessions.empty:\n",
    "            self.current_class = active_sessions.iloc[0]['class']\n",
    "            self.current_subject = active_sessions.iloc[0]['subject']\n",
    "            \n",
    "            self.class_label.config(text=f\"Class: {self.current_class}\")\n",
    "            self.subject_label.config(text=f\"Subject: {self.current_subject}\")\n",
    "    \n",
    "    def start_recognition(self):\n",
    "        \"\"\"Start face recognition\"\"\"\n",
    "        if not self.known_encodings and not os.path.exists(\"data/faces\"):\n",
    "            messagebox.showerror(\"Error\", \"No face data loaded! Please add faces to 'data/faces' folder.\")\n",
    "            return\n",
    "        \n",
    "        self.running = True\n",
    "        self.start_btn.config(state=tk.DISABLED)\n",
    "        self.stop_btn.config(state=tk.NORMAL)\n",
    "    \n",
    "    def stop_recognition(self):\n",
    "        \"\"\"Stop face recognition\"\"\"\n",
    "        self.running = False\n",
    "        self.start_btn.config(state=tk.NORMAL)\n",
    "        self.stop_btn.config(state=tk.DISABLED)\n",
    "    \n",
    "    def mark_attendance(self, name, status):\n",
    "        \"\"\"Log attendance with timestamp\"\"\"\n",
    "        now = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        new_entry = pd.DataFrame([[name, now, status, self.current_subject]], \n",
    "                               columns=['name', 'timestamp', 'status', 'subject'])\n",
    "        self.attendance_df = pd.concat([self.attendance_df, new_entry], ignore_index=True)\n",
    "        self.attendance_df.to_csv(self.ATTENDANCE_FILE, index=False)\n",
    "    \n",
    "    def update_attendance_display(self):\n",
    "        \"\"\"Update the attendance dashboard\"\"\"\n",
    "        self.tree.delete(*self.tree.get_children())\n",
    "        \n",
    "        today = datetime.now().date()\n",
    "        today_records = self.attendance_df[\n",
    "            pd.to_datetime(self.attendance_df['timestamp']).dt.date == today\n",
    "        ].sort_values('timestamp', ascending=False)\n",
    "        \n",
    "        for _, row in today_records.iterrows():\n",
    "            self.tree.insert(\"\", tk.END, values=(\n",
    "                row['name'],\n",
    "                row['timestamp'],\n",
    "                row['status'],\n",
    "                row['subject']\n",
    "            ))\n",
    "        \n",
    "        # Update summary\n",
    "        present_count = len(today_records[today_records['status'] == 'Present'])\n",
    "        unique_students = today_records[today_records['status'] == 'Present']['name'].nunique()\n",
    "        self.summary_label.config(\n",
    "            text=f\" Today's Attendance\\n Present: {unique_students} students\\n Total Records: {present_count}\"\n",
    "        )\n",
    "    \n",
    "    def update_camera_display(self):\n",
    "        \"\"\"Update camera feed in GUI\"\"\"\n",
    "        # Prioritize showing processed frames if available\n",
    "        if not self.processed_frame_queue.empty():\n",
    "            frame = self.processed_frame_queue.get()\n",
    "        elif not self.camera_queue.empty():\n",
    "            frame = self.camera_queue.get()\n",
    "        else:\n",
    "            frame = None\n",
    "        \n",
    "        if frame is not None:\n",
    "            img = Image.fromarray(frame)\n",
    "            imgtk = ImageTk.PhotoImage(image=img)\n",
    "            \n",
    "            self.camera_label.imgtk = imgtk\n",
    "            self.camera_label.configure(image=imgtk)\n",
    "        \n",
    "        self.root.after(30, self.update_camera_display)\n",
    "    \n",
    "    def export_attendance(self):\n",
    "        \n",
    "        \"\"\"Export attendance to CSV/Excel\"\"\"\n",
    "        if self.attendance_df.empty:\n",
    "            messagebox.showwarning(\"Warning\", \"No attendance data to export!\")\n",
    "            return\n",
    "\n",
    "    # Ask the user where to save the file\n",
    "    file_path = filedialog.asksaveasfilename(\n",
    "        defaultextension=\".csv\",\n",
    "        filetypes=[(\"CSV files\", \"*.csv\"), (\"Excel files\", \"*.xlsx\")],\n",
    "        title=\"Save attendance file\"\n",
    "    )\n",
    "    \n",
    "    if not file_path:\n",
    "        return  # User cancelled\n",
    "\n",
    "    try:\n",
    "        if file_path.endswith(\".csv\"):\n",
    "            self.attendance_df.to_csv(file_path, index=False)\n",
    "        elif file_path.endswith(\".xlsx\"):\n",
    "            self.attendance_df.to_excel(file_path, index=False)\n",
    "        else:\n",
    "            messagebox.showerror(\"Error\", \"Unsupported file type selected!\")\n",
    "            return\n",
    "\n",
    "        messagebox.showinfo(\"Success\", f\"Attendance exported successfully to:\\n{file_path}\")\n",
    "    except Exception as e:\n",
    "        messagebox.showerror(\"Error\", f\"Failed to export attendance:\\n{e}\")\n",
    "    \n",
    "    def on_close(self):\n",
    "        \"\"\"Cleanup before closing\"\"\"\n",
    "        self.running = False\n",
    "        if self.camera:\n",
    "            self.camera.release()\n",
    "        self.executor.shutdown(wait=False)\n",
    "        self.root.destroy()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    root = tk.Tk()\n",
    "    app = SmartAttendanceSystem(root)\n",
    "    root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "face_recognition_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
